# ğŸ§  Exam Heuristics Tips (EN)

Quick guide to spot correct/incorrect choices in Databricks GenAIâ€‘style questions.

## Bias
- âŒ If an option says â€œremove training data/remove information,â€ itâ€™s bad practice.
- âœ… Prefer â€œtag and filter at retrieval,â€ â€œbalance datasets,â€ â€œaudit bias,â€ â€œuse fairness metrics.â€
- Eliminate if: it proposes deleting information, ignoring bias metrics, or training only on a homogeneous subset.
- Likely correct if: it suggests tagging + Vector Search/metadata filters, bias evaluation, and balanced datasets.

## Hallucinations
- âŒ â€œIncrease temperatureâ€ or â€œtrust the LLM blindly.â€
- âœ… â€œUse RAG with verified sources,â€ â€œfact verification,â€ â€œLLMâ€‘asâ€‘aâ€‘judge,â€ â€œcite sources,â€ â€œimprove/structure prompts.â€
- Eliminate if: no external context, ignores citations, or only tweaks temperature as the fix.
- Likely correct if: adds RAG, verifies with sources, cites docs, or adds factâ€‘checking guardrails.

## Cost
- âŒ â€œAlways use the largest modelâ€ or â€œdonâ€™t measure tokens.â€
- âœ… â€œUse smaller models when applicable,â€ â€œresponse caching,â€ â€œprompt compression,â€ â€œmonitor tokens and cost/request,â€ â€œscaleâ€‘toâ€‘zero.â€
- Eliminate if: no cost/token measurement, or fixed 24/7 infra without need.
- Likely correct if: instruments cost metrics, uses autoâ€‘scaling, and selects model by cost/benefit.

## Latency
- âŒ â€œAdd unnecessary steps without parallelism.â€
- âœ… â€œParallelize chains,â€ â€œuse embeddings/Vector Search to reduce context,â€ â€œserve realâ€‘time with autoâ€‘scaling,â€ â€œoptimize batch/quantization (if selfâ€‘hosted).â€
- Eliminate if: loads the entire corpus into the prompt or uses a single unsized queue.
- Likely correct if: reduces context via semantic retrieval and uses autoâ€‘scalable infra.

## Availability
- âŒ â€œSingle endpoint without scaling/observability.â€
- âœ… â€œAutoâ€‘scaling,â€ â€œA/B or canary,â€ â€œmonitoring + alerts,â€ â€œcontrolled fallbacks.â€
- Eliminate if: no monitoring or redundancy.
- Likely correct if: endpoints with autoâ€‘scaling, A/B, and Inference Table capture.

## Drift
- âŒ â€œIgnore driftâ€ or â€œretrain without evidence.â€
- âœ… â€œLakehouse Monitoring (profile/drift/custom),â€ â€œretrain triggers with thresholds,â€ â€œversioning and comparison.â€
- Eliminate if: arbitrary retraining or no baseline comparison.
- Likely correct if: thresholds + retraining plan based on metrics.

## Quality
- âŒ â€œMeasure only one metricâ€ or â€œonly loss/perplexity.â€
- âœ… â€œTask metrics (BLEU/ROUGE) + relevance/faithfulness,â€ â€œhuman feedback,â€ â€œbenchmarks (MMLU, HellaSwag).â€
- Eliminate if: misuses metrics (e.g., BLEU for classification) or ignores feedback.
- Likely correct if: combines technical and product metrics (relevance, satisfaction).

## Security/Guardrails
- âŒ â€œTrust user instructionsâ€ or â€œallow PII/sensitive output.â€
- âœ… â€œInput/output guardrails (Llama Guard, PII checks, toxicity),â€ â€œprompt safety,â€ â€œrate limiting,â€ â€œauditing.â€
- Eliminate if: no input/output filtering or disabling controls.
- Likely correct if: integrates safety classification before and after the LLM.

## Retrieval (RAG)
- âŒ â€œIncrease context with no chunking/filters,â€ â€œmix different embedding models for docs/queries.â€
- âœ… â€œChunking with overlap,â€ â€œmetadata filters,â€ â€œsame model for docs and queries,â€ â€œreranking when needed.â€
- Eliminate if: dumps full documents into the prompt or skips metadata filters.
- Likely correct if: Vector Search + filters + rerank.

## Embeddings/Vector Search
- âŒ â€œChoose embeddings ignoring language/domain.â€
- âœ… â€œMultilingual/domainâ€‘fit embeddings,â€ â€œZâ€‘Ordering/Data Skipping,â€ â€œVector Search with filters.â€
- Eliminate if: uses different embedding models across index and query.
- Likely correct if: keeps the same vector space and optimizes storage/query.

## Model Choice
- âŒ â€œAlways proprietary externalâ€ or â€œalways open source.â€
- âœ… Decide by privacy, quality, cost, latency.
- Eliminate if: ignores compliance or timeâ€‘toâ€‘market.
- Likely correct if: aligns model type to case (internal privacy vs speed/quality).

## Governance (Unity Catalog)
- âŒ â€œAdâ€‘hoc permissions in each system.â€
- âœ… â€œCentral ACLs in UC,â€ â€œlineage/auditing,â€ â€œRegistry with aliases (@champion/@challenger).â€
- Eliminate if: no centralized control or traceability.
- Likely correct if: uses UC for permissions and endâ€‘toâ€‘end lineage.

## Evaluation
- âŒ â€œNo reference datasets nor clear metrics.â€
- âœ… â€œOffline + online,â€ â€œLLMâ€‘asâ€‘aâ€‘judge when references lack,â€ â€œA/B and canary.â€
- Eliminate if: decides without evidence or with a single isolated metric.
- Likely correct if: triangulates benchmarks, feedback, and controlled experiments.

## Privacy & Compliance
- Eliminate if: sends sensitive data to external APIs without guarantees or ignores GDPR/CCPA.
- Likely correct if: proposes selfâ€‘hosted/UCâ€‘secured models, anonymization/pseudonymization, and UC access control.

## Prompt Engineering (patterns)
- Eliminate if: vague prompt without role/instructions/format.
- Likely correct if: includes role, context, clear input and format; uses delimiters; fewâ€‘shot for structured output.

## Chunking vs Reranking
- Eliminate if: only â€œlarger chunksâ€ to improve retrieval.
- Likely correct if: chunking with overlap + filters; and reranking when topâ€‘K has noise.

## Vector DB vs Plugins
- Eliminate if: chooses a plugin with no governance/scale needs.
- Likely correct if: dedicated vector DB (Mosaic AI Vector Search) for CRUD, filters, ACLs, scalability.

## MLflow & Registry
- Eliminate if: deploys without versioning or aliases.
- Likely correct if: Registry in UC, aliases (@champion/@challenger), lineage for auditability.

## Traffic/Aâ€‘B/Canary
- Eliminate if: sends 50% to an unknown model initially.
- Likely correct if: starts with 5â€“10% canary and scales by metrics.

## Caching & Retries
- Eliminate if: reâ€‘queries identical prompts without cache or uses infinite retries.
- Likely correct if: cache for frequent prompts, retries with backoff and limits.

## Decoding (temperature/top_p)
- Eliminate if: raises temperature to â€œfixâ€ factual accuracy.
- Likely correct if: lower temperature for factual tasks; adjust top_p/top_k thoughtfully.

## Context Window / Lost in the Middle
- Eliminate if: dumps full documents into the prompt.
- Likely correct if: RAG + chunking + relevant passage selection.

## Multilingual
- Eliminate if: embeddings/model donâ€™t support the target language.
- Likely correct if: embeddings and LLM aligned to language/domain.

## Monitoring â€“ Thresholds
- Eliminate if: monitoring without thresholds/alerts.
- Likely correct if: defines p95/p99 latency, drift thresholds and alerts; logs to Inference Tables.
