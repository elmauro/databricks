# 2ï¸âƒ£ Desarrollo de Soluciones de IA Generativa

## ğŸ“š Tabla de Contenidos
1. [Prompt Engineering](#prompt-engineering)
2. [Â¿QuÃ© es RAG?](#quÃ©-es-rag)
3. [PreparaciÃ³n de Datos para RAG](#preparaciÃ³n-de-datos-para-rag)
4. [Chunking de Documentos](#chunking-de-documentos)
5. [Embeddings](#embeddings)
6. [Vector Search](#vector-search)
7. [Reranking](#reranking)
8. [MLflow para RAG](#mlflow-para-rag)
9. [EvaluaciÃ³n de RAG](#evaluaciÃ³n-de-rag)

---

## Prompt Engineering

### Â¿QuÃ© es un Prompt?

Un **prompt** es la instrucciÃ³n o pregunta que le das a un LLM.

**Ejemplo**:
```
Prompt: "Resume este artÃ­culo en 3 puntos"
LLM: [genera el resumen]
```

### Â¿QuÃ© es Prompt Engineering?

**DefiniciÃ³n**: El arte y prÃ¡ctica de **diseÃ±ar y refinar prompts** para obtener mejores resultados del LLM.

Es como aprender a hacer las preguntas correctas para obtener las respuestas que necesitas.

---

### Componentes de un Buen Prompt

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. INSTRUCCIONES                  â”‚
â”‚   "ActÃºa como experto en Python"   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   2. CONTEXTO                       â”‚
â”‚   "Para una aplicaciÃ³n web"        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   3. INPUT/PREGUNTA                 â”‚
â”‚   "Â¿CÃ³mo optimizo esta funciÃ³n?"   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   4. FORMATO DE OUTPUT              â”‚
â”‚   "Responde en formato JSON"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo Completo

âŒ **Prompt Malo**:
```
"Dame cÃ³digo"
```

âœ… **Prompt Bueno**:
```
INSTRUCCIONES: Eres un experto en Python para ciencia de datos.

CONTEXTO: Necesito analizar un dataset de ventas con pandas.

INPUT: Tengo un CSV con columnas: fecha, producto, cantidad, precio.
Quiero calcular ventas totales por mes.

FORMATO: Dame cÃ³digo Python con comentarios explicativos.
```

---

### TÃ©cnicas de Prompt Engineering

#### 1. Zero-Shot Prompting

**DefiniciÃ³n**: Pedir al LLM que haga algo **sin darle ejemplos**.

**CuÃ¡ndo usar**: Tareas simples y directas

**Ejemplo**:
```
Prompt: "Traduce 'Hello world' al espaÃ±ol"
LLM: "Hola mundo"
```

#### 2. Few-Shot Prompting

**DefiniciÃ³n**: Dar **algunos ejemplos** para guiar al LLM.

**CuÃ¡ndo usar**: Tareas con formato especÃ­fico o lÃ³gica compleja

**Ejemplo**:
```
Prompt:
Clasifica el sentimiento: positivo, negativo, neutral

Ejemplo 1:
Texto: "Me encantÃ³ este producto"
Sentimiento: positivo

Ejemplo 2:
Texto: "Terrible experiencia"
Sentimiento: negativo

Ahora clasifica:
Texto: "El servicio es aceptable"
Sentimiento: ?

LLM: "neutral"
```

#### 3. Chain-of-Thought (CoT) Prompting

**DefiniciÃ³n**: Pedir al LLM que **piense paso a paso** como un humano.

**CuÃ¡ndo usar**: Problemas que requieren razonamiento

**Ejemplo**:
```
Prompt:
Resuelve paso a paso:
Si una pizza cuesta $15 y tengo un descuento del 20%, Â¿cuÃ¡nto pago?

Piensa paso a paso:

LLM:
Paso 1: Calcular el 20% de $15
20% de $15 = $15 Ã— 0.20 = $3

Paso 2: Restar el descuento del precio original
$15 - $3 = $12

Respuesta: Pagas $12
```

#### 4. Prompt Chaining

**DefiniciÃ³n**: **Encadenar mÃºltiples prompts** donde el output de uno es input del siguiente.

**CuÃ¡ndo usar**: Tareas complejas que se dividen en pasos

**Ejemplo**:
```
Prompt 1: "Resume este artÃ­culo de 1000 palabras"
Output 1: [resumen de 200 palabras]

Prompt 2: "Traduce este resumen al francÃ©s: [Output 1]"
Output 2: [resumen en francÃ©s]

Prompt 3: "Extrae los 3 puntos clave de: [Output 2]"
Output 3: [3 puntos en francÃ©s]
```

**Diagrama**:
```
ArtÃ­culo â†’ [Resume] â†’ Resumen â†’ [Traduce] â†’ TraducciÃ³n â†’ [Extrae] â†’ Puntos clave
```

---

### Tips y Trucos de Prompt Engineering

#### 1. Usar Delimitadores

**Por quÃ©**: Separar claramente instrucciones de datos

**Delimitadores comunes**: `###`, ` ``` `, `{}`, `[]`, `---`

**Ejemplo**:
```
Analiza el siguiente texto:
---
[Tu texto aquÃ­]
---

Devuelve el anÃ¡lisis en este formato:
```json
{
  "tema": "...",
  "sentimiento": "..."
}
```
```

#### 2. Especificar Formato de Output

**Ejemplos**:
- "Responde en formato JSON"
- "Genera una tabla markdown"
- "Usa bullets points"
- "Dame cÃ³digo Python con comentarios"

#### 3. Dar un Ejemplo Correcto

```
Prompt:
Necesito que formatees direcciones asÃ­:

Ejemplo correcto:
Input: "calle 123 ciudad xyz"
Output: "Calle: 123, Ciudad: XYZ"

Ahora formatea: "avenida 456 pueblo abc"
```

#### 4. Guiar para Mejores Respuestas

âœ… **Pide que NO alucine**:
```
"Si no sabes la respuesta, di 'No tengo informaciÃ³n suficiente'.
No inventes datos."
```

âœ… **Pide que NO asuma informaciÃ³n sensible**:
```
"No asumas informaciÃ³n personal del usuario.
Si necesitas datos, pregunta explÃ­citamente."
```

âœ… **Pide que piense mÃ¡s (CoT)**:
```
"No te apresures a una soluciÃ³n.
Piensa paso a paso y muestra tu razonamiento."
```

---

### Beneficios y Limitaciones

#### âœ… Beneficios
- **Simple y Eficiente**: No requiere reentrenamiento
- **Resultados Predecibles**: Con buenos prompts, outputs consistentes
- **Salidas Personalizadas**: Control sobre formato y estilo

#### âŒ Limitaciones
- **Depende del modelo**: Un prompt que funciona en GPT-4 puede fallar en LLaMA
- **Limitado por conocimiento del modelo**: Si el modelo no sabe algo, prompt engineering no ayuda
- **Necesitas RAG para conocimiento externo**: Datos actualizados o privados requieren RAG

---

## Â¿QuÃ© es RAG?

### DefiniciÃ³n Simple

**RAG** = **Retrieval-Augmented Generation**

Es una tÃ©cnica que **combina bÃºsqueda de informaciÃ³n + generaciÃ³n de respuestas**.

### Â¿CÃ³mo funciona?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Usuario pregunta algo                    â”‚
â”‚     "Â¿CuÃ¡l es la polÃ­tica de vacaciones?"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. RETRIEVAL (BÃºsqueda)                     â”‚
â”‚     Busca en documentos relevantes           â”‚
â”‚     Encuentra: manual_empleados.pdf          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. AUGMENTATION (Aumentar el prompt)        â”‚
â”‚     Prompt: "Basado en este contexto:        â”‚
â”‚     [contenido del manual]                   â”‚
â”‚     Responde: Â¿polÃ­tica de vacaciones?"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. GENERATION (Generar respuesta)           â”‚
â”‚     LLM lee el contexto y genera respuesta   â”‚
â”‚     "SegÃºn el manual, tienes 15 dÃ­as..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Â¿Por quÃ© es importante RAG?

#### Problema sin RAG:
```
Pregunta: "Â¿CuÃ¡l es nuestro nuevo producto de marzo 2024?"
LLM: "No tengo informaciÃ³n actualizada posterior a 2023" âŒ
```

#### SoluciÃ³n con RAG:
```
Pregunta: "Â¿CuÃ¡l es nuestro nuevo producto de marzo 2024?"

RAG:
1. Busca en documentos â†’ encuentra "Lanzamiento_Marzo2024.pdf"
2. Extrae contexto â†’ "Producto X lanzado el 15 de marzo"
3. LLM genera â†’ "El 15 de marzo 2024 lanzamos el Producto X..." âœ…
```

### Casos de Uso de RAG

| Caso de Uso | DescripciÃ³n | Ejemplo |
|-------------|-------------|---------|
| **Q&A Chatbot** | Responde preguntas sobre documentos | Chatbot de soporte tÃ©cnico |
| **Search Augmentation** | Mejora resultados de bÃºsqueda | Google + resumen AI |
| **Content Creation** | Genera contenido basado en fuentes | Resumen de mÃºltiples papers |
| **Summarization** | Resume documentos largos | Executive summary de reportes |

### Arquitectura RAG en Databricks

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: DOCUMENT EMBEDDING (PreparaciÃ³n)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  External Sources (PDFs, Docs, etc.)               â”‚
â”‚         â†“                                           â”‚
â”‚  Delta Live Tables (Ingestion batch/streaming)     â”‚
â”‚         â†“                                           â”‚
â”‚  Files & Metadata (Delta Tables)                   â”‚
â”‚         â†“                                           â”‚
â”‚  Document Processing (Chunking, cleaning)          â”‚
â”‚         â†“                                           â”‚
â”‚  Mosaic AI Model Serving (Embeddings)              â”‚
â”‚         â†“                                           â”‚
â”‚  Mosaic AI Vector Search (Storage)                 â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: QUERY & RETRIEVAL (Uso)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  User Query                                         â”‚
â”‚         â†“                                           â”‚
â”‚  Mosaic AI Model Serving (Embed query)             â”‚
â”‚         â†“                                           â”‚
â”‚  Mosaic AI Vector Search (Find similar docs)       â”‚
â”‚         â†“                                           â”‚
â”‚  Retrieved Context                                  â”‚
â”‚         â†“                                           â”‚
â”‚  Prompt Augmentation (Add context to prompt)       â”‚
â”‚         â†“                                           â”‚
â”‚  Mosaic AI Model Serving (LLM Generation)          â”‚
â”‚         â†“                                           â”‚
â”‚  Response                                           â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## PreparaciÃ³n de Datos para RAG

### Problemas Potenciales

| Problema | DescripciÃ³n | Impacto |
|----------|-------------|---------|
| **Poor Quality Output** | Datos sucios/incorrectos | Respuestas incorrectas |
| **Lost in the Middle** | LLM ignora docs del medio | InformaciÃ³n importante perdida |
| **Inefficient Retrieval** | Datos mal preparados | BÃºsqueda lenta/inexacta |
| **Exposing Data** | Mala gobernanza | Violaciones de seguridad |
| **Wrong Embedding Model** | Modelo inadecuado | Baja calidad de bÃºsqueda |

### Proceso de PreparaciÃ³n de Datos

```
1. INGESTION & PRE-PROCESSING
   â€¢ Cargar documentos (PDF, Word, HTML, etc.)
   â€¢ Limpiar y normalizar
   â€¢ Extraer texto

2. DATA STORAGE & GOVERNANCE
   â€¢ Guardar en Delta Lake
   â€¢ Configurar Unity Catalog (permisos)

3. CHUNKING
   â€¢ Dividir documentos en chunks
   â€¢ Fixed-size o Context-aware

4. EMBEDDING
   â€¢ Convertir chunks a vectores
   â€¢ Usar modelo de embeddings apropiado

5. VECTOR STORE
   â€¢ Guardar en Mosaic AI Vector Search
   â€¢ Indexar para bÃºsqueda rÃ¡pida
```

---

## Chunking de Documentos

### Â¿QuÃ© es Chunking?

**DefiniciÃ³n**: Dividir documentos largos en **pedazos (chunks)** mÃ¡s pequeÃ±os.

**Â¿Por quÃ©?**:
- LLMs tienen lÃ­mite de tokens (ej. 8k, 32k, 128k)
- Chunks mÃ¡s pequeÃ±os = bÃºsqueda mÃ¡s precisa
- Mejor retrieval de informaciÃ³n relevante

### VisualizaciÃ³n del Problema

```
âŒ Sin Chunking:
[Documento completo de 10,000 palabras]
â†“
LLM (lÃ­mite: 4,000 tokens)
â†“
ERROR: Excede lÃ­mite

âœ… Con Chunking:
[Chunk 1: 500 palabras]
[Chunk 2: 500 palabras]
[Chunk 3: 500 palabras]
...
â†“
Solo envÃ­as los chunks relevantes al LLM
â†“
âœ… Funciona perfectamente
```

---

### Estrategias de Chunking

#### 1. Fixed-Size Chunking (TamaÃ±o Fijo)

**CÃ³mo funciona**: Divide cada X tokens/caracteres

**Ejemplo**:
```
Documento: "Este es un documento largo sobre Python. Python es un lenguaje 
            de programaciÃ³n. Se usa mucho en ciencia de datos..."

Chunk 1 (50 chars): "Este es un documento largo sobre Python. Python"
Chunk 2 (50 chars): " es un lenguaje de programaciÃ³n. Se usa mucho "
Chunk 3 (50 chars): "en ciencia de datos..."
```

**Pros**:
- âœ… Simple
- âœ… RÃ¡pido
- âœ… Barato computacionalmente

**Contras**:
- âŒ Puede cortar en medio de una oraciÃ³n
- âŒ Pierde contexto
- âŒ No respeta estructura del documento

#### 2. Context-Aware Chunking (Consciente del Contexto)

**CÃ³mo funciona**: Divide respetando estructura lÃ³gica

**Opciones**:
- Por oraciÃ³n
- Por pÃ¡rrafo
- Por secciÃ³n (H1, H2, H3 en HTML/Markdown)
- Por puntuaciÃ³n especial (`.`, `\n`)

**Ejemplo**:
```
Documento markdown:
# SecciÃ³n 1: IntroducciÃ³n
Este es el pÃ¡rrafo de introducciÃ³n.

## SubsecciÃ³n 1.1
Contenido de la subsecciÃ³n.

# SecciÃ³n 2: Desarrollo
...

Chunks generados:
Chunk 1: "# SecciÃ³n 1: IntroducciÃ³n\nEste es el pÃ¡rrafo de introducciÃ³n."
Chunk 2: "## SubsecciÃ³n 1.1\nContenido de la subsecciÃ³n."
Chunk 3: "# SecciÃ³n 2: Desarrollo\n..."
```

**Pros**:
- âœ… Mantiene contexto
- âœ… Respeta estructura
- âœ… MÃ¡s semÃ¡nticamente coherente

**Contras**:
- âŒ MÃ¡s complejo
- âŒ Chunks de tamaÃ±o variable

#### 3. Chunking con Overlap (SuperposiciÃ³n)

**Problema**: InformaciÃ³n importante en la frontera entre chunks

**SoluciÃ³n**: Overlap (superposiciÃ³n) entre chunks consecutivos

**VisualizaciÃ³n**:
```
Sin Overlap:
[Chunk 1: AAAA] [Chunk 2: BBBB] [Chunk 3: CCCC]

Con Overlap:
[Chunk 1: AAAA][AA]
            [AA][Chunk 2: BBBB][BB]
                            [BB][Chunk 3: CCCC]
                            
Overlap de 2 caracteres entre chunks
```

**Ejemplo PrÃ¡ctico**:
```
Texto original: "Python es fÃ¡cil. AdemÃ¡s, Python es poderoso."

Sin overlap:
Chunk 1: "Python es fÃ¡cil."
Chunk 2: "AdemÃ¡s, Python es poderoso."
â†’ Se pierde la conexiÃ³n entre chunks

Con overlap (5 palabras):
Chunk 1: "Python es fÃ¡cil. AdemÃ¡s,"
Chunk 2: "AdemÃ¡s, Python es poderoso."
â†’ Mantiene contexto
```

#### 4. Windowed Summarization (Resumen con Ventana)

**CÃ³mo funciona**: Cada chunk incluye un resumen de chunks anteriores

**Ejemplo**:
```
Chunk 1: 
"Python es un lenguaje de programaciÃ³n."

Chunk 2:
[Resumen anterior: "IntroducciÃ³n a Python"]
"Python se usa en ciencia de datos..."

Chunk 3:
[Resumen anterior: "Python en ciencia de datos"]
"Las librerÃ­as principales son NumPy, Pandas..."
```

---

### Herramientas de Chunking

- **ChunkViz**: Herramienta visual para probar estrategias
- **LangChain**: Text splitters (RecursiveCharacterTextSplitter)
- **LlamaIndex**: NodeParser
- **Unstructured**: Auto-chunking inteligente

---

### DesafÃ­os con Documentos Complejos

#### Tipos de Contenido Complejo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Documento PDF Complejo             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Texto mezclado con imÃ¡genes      â”‚
â”‚  â€¢ Tablas con datos                 â”‚
â”‚  â€¢ Diagramas e infogrÃ¡ficos         â”‚
â”‚  â€¢ MÃºltiples columnas               â”‚
â”‚  â€¢ Texto con colores (jerarquÃ­a)    â”‚
â”‚  â€¢ Headers y footers                â”‚
â”‚  â€¢ Watermarks                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Soluciones

**1. LibrerÃ­as Tradicionales**:
- **PyMuPDF**: ExtracciÃ³n bÃ¡sica de texto
- **PyPDF**: Similar, simple
- **pdfplumber**: Mejor con tablas

**LimitaciÃ³n**: No entienden layout complejo

**2. Layout Models** (Modelos de DiseÃ±o):
- **Donut**: OCR-free document understanding
- **doctr**: Document text recognition
- **Unstructured.io**: Multi-format parsing
- **Hugging Face Layout Models**: LayoutLM, LayoutLMv3

**Ventaja**: Entienden estructura visual

**3. Multi-Modal Models** (Modelos Multi-Modales):
- **GPT-4 Vision**: Procesa imagen + texto
- **Claude Vision**: Similar
- **Open Source**: LLaVA, Fuyu

**Ventaja**: Procesn imagen completa, extraen texto e interpretan diagramas

---

## Embeddings

### Â¿QuÃ© es un Embedding?

Una **representaciÃ³n numÃ©rica** (vector) de contenido textual.

**Ejemplo Visual**:
```
Texto: "perro"
Embedding: [0.2, 0.8, 0.1, 0.5, ...] (vector de 384 dimensiones)

Texto: "gato"
Embedding: [0.3, 0.7, 0.2, 0.4, ...] (similar a "perro" porque son animales)

Texto: "automÃ³vil"
Embedding: [0.8, 0.1, 0.9, 0.2, ...] (muy diferente)
```

### Â¿Por quÃ© son importantes?

Los embeddings capturan **significado semÃ¡ntico**:

```
"perro" vs "can" (sinÃ³nimos)
â†’ Embeddings muy similares

"banco" (asiento) vs "banco" (financiero)
â†’ Embeddings diferentes (contexto importa)
```

### CÃ³mo se usan en RAG

```
1. INDEXING (Una vez)
   Documentos â†’ Embedding Model â†’ Vectores â†’ Vector DB

2. QUERY (Cada bÃºsqueda)
   Query â†’ Embedding Model â†’ Vector query â†’ 
   Vector DB busca vectores similares â†’ Documentos relevantes
```

---

### Elegir el Modelo de Embeddings Correcto

#### Consideraciones

**1. Propiedades del Texto**:
- **Vocabulario**: Â¿EspaÃ±ol, inglÃ©s, tÃ©cnico?
- **Dominio**: Â¿MÃ©dico, legal, general?
- **Longitud**: Â¿Tweets cortos o documentos largos?

**2. Capacidades del Modelo**:
- **Multi-idioma**: Â¿Necesitas soporte para varios idiomas?
- **Dimensiones**: MÃ¡s dimensiones = mÃ¡s precisiÃ³n, pero mÃ¡s costo

**3. Consideraciones PrÃ¡cticas**:
- **Context window**: Â¿CuÃ¡ntos tokens acepta?
- **Privacidad**: Â¿API externa o local?
- **Costo**: Â¿Gratis, open-source, o pago?
- **Benchmark**: Probar varios y comparar

#### Modelos Populares

| Modelo | Dimensiones | Idiomas | Contexto | Tipo |
|--------|-------------|---------|----------|------|
| **BGE-Large** | 1024 | Multi | 512 tokens | Open Source |
| **E5** | 768 | Multi | 512 tokens | Open Source |
| **OpenAI Ada** | 1536 | Multi | 8191 tokens | Propietario |
| **Cohere Embed** | 4096 | Multi | Variable | Propietario |

---

### Tip 1: Elige Tu Modelo Sabiamente

**Problema**: Modelo de embeddings entrenado en inglÃ©s tÃ©cnico falla con espaÃ±ol coloquial

**SoluciÃ³n**: El modelo debe:
- âœ… Estar entrenado en datos similares a los tuyos
- âœ… Soportar tu(s) idioma(s)
- âœ… Entender tu dominio (mÃ©dico, legal, etc.)

### Tip 2: Mismo Espacio de Embeddings

**Problema**: Queries y documentos con modelos diferentes

**Ejemplo ERROR**:
```
Documentos embedded con: modelo_A
Queries embedded con: modelo_B
â†’ Vectores incomparables âŒ
```

**SoluciÃ³n**:
```
âœ… Usa el MISMO modelo para docs y queries
âœ… O entrena con datos similares
```

---

## Vector Search

### Â¿QuÃ© es una Base de Datos Vectorial?

**DefiniciÃ³n**: Base de datos optimizada para **almacenar y buscar vectores** (embeddings).

**Diferencia con DB tradicional**:

```
DB Tradicional (SQL):
SELECT * FROM products WHERE name = 'iPhone'
â†’ BÃºsqueda exacta por palabra

Vector DB:
query = "telÃ©fono inteligente"
â†’ Encuentra: iPhone, Samsung Galaxy, etc.
â†’ BÃºsqueda por SIGNIFICADO
```

### Propiedades de Vector DB

- **CRUD**: Create, Read, Update, Delete
- **Indexing**: Organiza vectores para bÃºsqueda rÃ¡pida
- **ANN**: Approximate Nearest Neighbor (bÃºsqueda rÃ¡pida aprox)
- **Filtering**: Soporta filtros metadata (WHERE clauses)
- **Scalability**: Maneja millones/billones de vectores

---

### MÃ©tricas de Similitud

#### 1. Euclidean Distance (Distancia Euclidiana)

**QuÃ© mide**: Distancia "en lÃ­nea recta" entre dos puntos

**FÃ³rmula**: âˆš((xâ‚-xâ‚‚)Â² + (yâ‚-yâ‚‚)Â² + ...)

**CuÃ¡ndo usar**: Cuando la magnitud importa

**Ejemplo**:
```
Vector A: [1, 2]
Vector B: [4, 6]

Distancia = âˆš((1-4)Â² + (2-6)Â²) = âˆš(9 + 16) = âˆš25 = 5

InterpretaciÃ³n: Menor distancia = mÃ¡s similar
```

#### 2. Cosine Similarity (Similitud Coseno)

**QuÃ© mide**: Ãngulo entre vectores (ignora magnitud)

**Rango**: -1 (opuestos) a 1 (idÃ©nticos)

**CuÃ¡ndo usar**: Textos (la frecuencia absoluta no importa, solo la proporciÃ³n)

**Ejemplo Visual**:
```
Vector A: [10, 0]
Vector B: [5, 0]

Distancia Euclidiana: Grande (5)
Cosine Similarity: 1.0 (misma direcciÃ³n)

â†’ Son similares semÃ¡nticamente aunque diferentes en magnitud
```

---

### Algoritmos de Vector Search

#### K-Nearest Neighbors (KNN)

**QuÃ© hace**: Encuentra los K vecinos mÃ¡s cercanos

**Problema**: Lento con millones de vectores (compara con todos)

**SoluciÃ³n**: Approximate Nearest Neighbor (ANN)

#### Algoritmos ANN Populares

| Algoritmo | Creador | CaracterÃ­sticas |
|-----------|---------|-----------------|
| **ANNOY** | Spotify | Usa Ã¡rboles binarios, rÃ¡pido |
| **HNSW** | - | Hierarchical NSW, muy preciso |
| **FAISS** | Facebook | Altamente optimizado, GPU |
| **ScaNN** | Google | State-of-the-art, scalable |

---

### Vector DB vs Vector Libraries/Plugins

#### Vector Libraries (ej. FAISS, ANNOY)

**Pros**:
- âœ… Simple
- âœ… RÃ¡pido para datasets pequeÃ±os

**Contras**:
- âŒ No soportan CRUD completo
- âŒ Todo en memoria (RAM)
- âŒ No soportan queries complejas (WHERE)
- âŒ No replicaciÃ³n

**CuÃ¡ndo usar**: Prototipos, datos estÃ¡ticos pequeÃ±os

#### Vector Plugins (ej. pgvector, elasticsearch)

**Pros**:
- âœ… Se integran con DB existente

**Contras**:
- âŒ Funcionalidad limitada
- âŒ Menos optimizado que vector DB dedicada

**CuÃ¡ndo usar**: Ya tienes esa DB y no quieres aÃ±adir otra

#### Vector DB Dedicada (ej. Mosaic AI Vector Search)

**Pros**:
- âœ… Full CRUD
- âœ… Queries complejas (filtros metadata)
- âœ… Escalabilidad
- âœ… ReplicaciÃ³n y alta disponibilidad
- âœ… Gobernanza (Unity Catalog)

**CuÃ¡ndo usar**: ProducciÃ³n, datos grandes, requirements de gobernanza

---

### Mosaic AI Vector Search (Databricks)

#### CaracterÃ­sticas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MOSAIC AI VECTOR SEARCH                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Integrado con Lakehouse                 â”‚
â”‚  âœ… Auto-sync con Delta Tables              â”‚
â”‚  âœ… Unity Catalog (ACLs, governance)        â”‚
â”‚  âœ… Scalable y low-latency                  â”‚
â”‚  âœ… REST API + Python SDK                   â”‚
â”‚  âœ… Soporta filtros metadata                â”‚
â”‚  âœ… Managed (zero ops overhead)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source Delta Table                              â”‚
â”‚  (docs, chunks, metadata)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Auto Sync
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MOSAIC AI VECTOR SEARCH ENGINE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Indexer (crea Ã­ndices)                        â”‚
â”‚  â€¢ Vector DB (almacena vectores)                 â”‚
â”‚  â€¢ Query Engine (procesa queries)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MOSAIC AI MODEL SERVING                         â”‚
â”‚  (Embedding Models)                              â”‚
â”‚  â€¢ Custom Models                                 â”‚
â”‚  â€¢ Foundation Models (BGE, E5)                   â”‚
â”‚  â€¢ External Models (OpenAI, Cohere)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Setup de Vector Search

```python
# Paso 1: Crear Vector Search Endpoint
from databricks.vector_search.client import VectorSearchClient

vsc = VectorSearchClient()

vsc.create_endpoint(
    name="mi_endpoint",
    endpoint_type="STANDARD"
)

# Paso 2: Crear Ã­ndice desde Delta Table
vsc.create_delta_sync_index(
    endpoint_name="mi_endpoint",
    index_name="mi_catalogo.mi_schema.mi_indice",
    source_table_name="mi_catalogo.mi_schema.mi_tabla_docs",
    pipeline_type="TRIGGERED",  # o "CONTINUOUS"
    primary_key="id",
    embedding_source_column="text",  # columna con texto
    embedding_model_endpoint_name="mi_embedding_endpoint"
)

# Paso 3: Buscar documentos similares
results = vsc.get_index(
    "mi_catalogo.mi_schema.mi_indice"
).similarity_search(
    query_text="Â¿CÃ³mo usar Databricks?",
    columns=["id", "text", "metadata"],
    num_results=5
)
```

---

## Reranking

### Â¿QuÃ© es Reranking?

**Problema**: Vector search devuelve top-K resultados, pero no todos son igualmente relevantes

**SoluciÃ³n**: **Reranking** = reordenar resultados por relevancia usando un modelo mÃ¡s sofisticado

### Proceso

```
1. INITIAL RETRIEVAL (RÃ¡pido)
   Query â†’ Vector Search â†’ Top 100 documentos

2. RERANKING (Preciso)
   Query + Top 100 â†’ Reranker Model â†’ Top 10 mÃ¡s relevantes reordenados

3. GENERATION
   Query + Top 10 reranked â†’ LLM â†’ Respuesta
```

### Ejemplo

**Query**: "Â¿CÃ³mo hacer reset de contraseÃ±a?"

**Sin Reranking**:
```
Resultados Vector Search (top 5):
1. "Reset de contraseÃ±a de Facebook" (score: 0.85)
2. "Tutorial general de seguridad" (score: 0.83)
3. "Reset de contraseÃ±a de nuestro sistema" (score: 0.82) â† El mejor
4. "Historia de la contraseÃ±a" (score: 0.81)
5. "ContraseÃ±as seguras tips" (score: 0.80)
```

**Con Reranking**:
```
Resultados Reranked (top 5):
1. "Reset de contraseÃ±a de nuestro sistema" (score: 0.95) âœ…
2. "Reset de contraseÃ±a de Facebook" (score: 0.70)
3. "Tutorial general de seguridad" (score: 0.60)
4. "ContraseÃ±as seguras tips" (score: 0.55)
5. "Historia de la contraseÃ±a" (score: 0.40)
```

### Rerankers Populares

#### Open Source
- **Cross-Encoders**: BERT fine-tuned para reranking
- **bge-reranker-base**: BGE model especÃ­fico
- **FlashRank**: Ultra-rÃ¡pido y ligero

#### Propietarios
- **Cohere Rerank**: API de Cohere
- **Jina Reranker**: Jina AI

### Beneficios vs DesafÃ­os

#### âœ… Beneficios
- Mejora precisiÃ³n de retrieval
- Reduce hallucinations (LLM recibe mejor contexto)
- Mayor relevancia de respuestas

#### âŒ DesafÃ­os
- AÃ±ade latencia (llamada extra)
- Aumenta costo (otro modelo)
- MÃ¡s complejidad en pipeline

---

## MLflow para RAG

### Â¿QuÃ© es MLflow?

**DefiniciÃ³n**: Plataforma open-source para gestionar el **ciclo de vida completo** de modelos ML y GenAI.

**Co-desarrollado por**: Databricks

### MLflow Tracking

**Para quÃ©**: Registrar experimentos y comparar

**QuÃ© registra**:
- ParÃ¡metros del LLM (temperatura, max_tokens, etc.)
- MÃ©tricas (accuracy, latency, cost, etc.)
- Artifacts (modelos, prompts, chains, outputs)
- Source code del experimento

**Ejemplo**:
```python
import mlflow

with mlflow.start_run():
    # Registrar parÃ¡metros
    mlflow.log_param("model", "gpt-4")
    mlflow.log_param("temperature", 0.7)
    
    # Tu cÃ³digo RAG aquÃ­
    response = my_rag_chain(query)
    
    # Registrar mÃ©tricas
    mlflow.log_metric("latency", 1.5)  # segundos
    mlflow.log_metric("relevance_score", 0.95)
    
    # Registrar artifacts
    mlflow.log_artifact("prompt_template.txt")
```

---

### MLflow Model (Flavors)

**Â¿QuÃ© es un "flavor"?**: Formato estÃ¡ndar para empaquetar modelos

**Estructura**:
```
mi_modelo/
  â”œâ”€â”€ MLmodel  (archivo metadata)
  â”œâ”€â”€ conda.yaml  (dependencias)
  â”œâ”€â”€ requirements.txt
  â””â”€â”€ model/  (archivos del modelo)
```

**Flavors soportados**:
- `mlflow.pyfunc` (Python function - genÃ©rico)
- `mlflow.langchain` (Chains de LangChain)
- `mlflow.openai` (Modelos OpenAI)
- `mlflow.transformers` (Hugging Face)
- `mlflow.pytorch`, `mlflow.tensorflow`, etc.

---

### MLflow Model Registry (en Unity Catalog)

**Para quÃ©**: Organizar, versionar y desplegar modelos

**CaracterÃ­sticas**:
- âœ… Versioning automÃ¡tico
- âœ… Aliases (`@champion`, `@challenger`)
- âœ… Lifecycle management (dev â†’ staging â†’ prod)
- âœ… Collaboration y ACLs (Unity Catalog)
- âœ… Full lineage (quÃ© datos, cÃ³digo, params usÃ³)
- âœ… Tagging y anotaciones

**Ejemplo**:
```python
# Registrar modelo en Unity Catalog
mlflow.set_registry_uri("databricks-uc")

model_uri = f"runs:/{run_id}/model"
registered_model = mlflow.register_model(
    model_uri,
    "mi_catalogo.mi_schema.mi_rag_chatbot"
)

# Asignar alias
from mlflow import MlflowClient
client = MlflowClient()

client.set_registered_model_alias(
    "mi_catalogo.mi_schema.mi_rag_chatbot",
    "champion",
    version=3
)
```

---

## EvaluaciÃ³n de RAG

### Â¿QuÃ© evaluar en RAG?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG PIPELINE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. CHUNKING                           â”‚
â”‚     â†“                                  â”‚
â”‚     Evaluar: Chunk size, overlap, etc. â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. RETRIEVAL                          â”‚
â”‚     â†“                                  â”‚
â”‚     Evaluar: Precision, Recall, etc.   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. GENERATION                         â”‚
â”‚     â†“                                  â”‚
â”‚     Evaluar: Relevance, Faithfulness   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### MÃ©tricas Clave de EvaluaciÃ³n

#### 1. Context Precision

**QuÃ© mide**: Â¿Los documentos retrieved son relevantes?

**FÃ³rmula**: (Docs relevantes retrieved) / (Total docs retrieved)

**Ejemplo**:
```
Query: "Â¿CÃ³mo resetear contraseÃ±a?"
Retrieved: 5 docs
Relevantes: 3 docs

Context Precision = 3/5 = 0.6
```

#### 2. Context Recall

**QuÃ© mide**: Â¿Recuperamos TODOS los documentos relevantes?

**FÃ³rmula**: (Docs relevantes retrieved) / (Total docs relevantes en DB)

**Ejemplo**:
```
Docs relevantes en DB: 10
Retrieved: 5 docs (todos relevantes)

Context Recall = 5/10 = 0.5
```

**InterpretaciÃ³n**: Recall bajo = nos estamos perdiendo info importante

#### 3. Context Relevance

**QuÃ© mide**: Â¿El contexto retrieved es pertinente a la query?

**MediciÃ³n**: LLM-as-a-judge evalÃºa cada doc

**Ejemplo**:
```
Query: "PolÃ­tica de vacaciones"

Doc 1: "Empleados tienen 15 dÃ­as de vacaciones" â†’ Alta relevancia
Doc 2: "Historia de la empresa fundada en 1990" â†’ Baja relevancia
```

#### 4. Faithfulness (Fidelidad)

**QuÃ© mide**: Â¿La respuesta es fiel al contexto? (No alucina)

**FÃ³rmula**: (Claims en respuesta soportados por contexto) / (Total claims)

**Ejemplo**:
```
Contexto: "Empleados tienen 15 dÃ­as de vacaciones"

Respuesta LLM: "Tienes 15 dÃ­as de vacaciones pagadas"
â†’ "15 dÃ­as" âœ… (en contexto)
â†’ "pagadas" âŒ (no mencionado)

Faithfulness = 1/2 = 0.5 (baja fidelidad)
```

#### 5. Answer Relevancy (Relevancia de Respuesta)

**QuÃ© mide**: Â¿La respuesta realmente contesta la pregunta?

**Ejemplo**:
```
Query: "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo?"

Respuesta 1: "Tienes 15 dÃ­as de vacaciones al aÃ±o"
â†’ Alta relevancia âœ…

Respuesta 2: "Las vacaciones son importantes para el bienestar"
â†’ Baja relevancia âŒ (no responde)
```

#### 6. Answer Correctness (CorrecciÃ³n)

**QuÃ© mide**: Â¿La respuesta es factualmente correcta?

**Requiere**: Ground truth (respuesta correcta conocida)

**Ejemplo**:
```
Query: "Â¿Capital de Francia?"

Ground Truth: "ParÃ­s"
Respuesta LLM: "ParÃ­s"
â†’ Correctness = 1.0 âœ…

Respuesta LLM: "Lyon"
â†’ Correctness = 0.0 âŒ
```

---

### MLflow LLM Evaluation

**CaracterÃ­sticas**:
- âœ… Batch evaluation (muchas queries a la vez)
- âœ… ComparaciÃ³n de mÃºltiples modelos/prompts
- âœ… MÃ©tricas automÃ¡ticas (toxicity, perplexity, etc.)
- âœ… LLM-as-a-judge integrado
- âœ… Cost-effective

**Ejemplo**:
```python
import mlflow

# Dataset de evaluaciÃ³n
eval_data = pd.DataFrame({
    "query": ["Â¿CÃ³mo resetear contraseÃ±a?", "Â¿PolÃ­tica de vacaciones?"],
    "ground_truth": ["Ir a Settings > Reset", "15 dÃ­as al aÃ±o"]
})

# Evaluar modelo
results = mlflow.evaluate(
    model="models:/mi_rag_chatbot@champion",
    data=eval_data,
    targets="ground_truth",
    model_type="question-answering",
    evaluators=["default"]
)

# Ver resultados
print(results.metrics)
```

---

## ğŸ¯ Preguntas de PrÃ¡ctica

### Pregunta 1
**Â¿QuÃ© tÃ©cnica de prompting darÃ­as ejemplos al LLM?**

A) Zero-shot  
B) Few-shot âœ…  
C) Chain-of-Thought  
D) Prompt Chaining

**Respuesta**: B - Few-shot = dar ejemplos

---

### Pregunta 2
**Â¿QuÃ© soluciona RAG?**

A) Problemas de latencia  
B) Knowledge gap del LLM âœ…  
C) Costo del modelo  
D) Sesgo en datos

**Respuesta**: B - RAG aÃ±ade conocimiento externo actualizado

---

### Pregunta 3
**Â¿QuÃ© estrategia de chunking respeta la estructura del documento?**

A) Fixed-size  
B) Context-aware âœ…  
C) Random chunking  
D) No chunking

**Respuesta**: B - Context-aware divide por secciones/pÃ¡rrafos

---

### Pregunta 4
**Â¿QuÃ© mÃ©trica mide si la respuesta es fiel al contexto?**

A) Context Precision  
B) Faithfulness âœ…  
C) Answer Relevancy  
D) Perplexity

**Respuesta**: B - Faithfulness = no alucinar

---

### Pregunta 5
**Para queries y documentos en vector search, Â¿quÃ© es importante?**

A) Usar modelos diferentes  
B) Usar el mismo modelo de embeddings âœ…  
C) Embeddings de diferentes dimensiones  
D) No importa

**Respuesta**: B - Mismo modelo = mismo espacio vectorial

---

## ğŸ“ Resumen Ejecutivo

### Lo que DEBES saber:

âœ… **Prompt Engineering**: Zero-shot, Few-shot, Chain-of-Thought, Prompt Chaining  
âœ… **RAG** = Retrieval + Augmentation + Generation (soluciona knowledge gap)  
âœ… **Chunking**: Fixed-size (simple) vs Context-aware (mejor), usar overlap  
âœ… **Embeddings**: Representaciones vectoriales, mismo modelo para queries y docs  
âœ… **Vector Search**: Busca por significado (semÃ¡ntica), no por palabra exacta  
âœ… **Mosaic AI Vector Search**: Integrado con Lakehouse, Unity Catalog, auto-sync  
âœ… **Reranking**: Mejora precisiÃ³n reordenando resultados  
âœ… **MLflow**: Tracking, Registry (Unity Catalog), Evaluation  
âœ… **MÃ©tricas RAG**: Context Precision/Recall, Faithfulness, Answer Relevancy/Correctness

---

## ğŸ”— PrÃ³ximo Tema

â¡ï¸ **ContinÃºa con**: `03_Desarrollo_Aplicaciones.md` (Compound AI Systems, Agents, Multi-modal)

