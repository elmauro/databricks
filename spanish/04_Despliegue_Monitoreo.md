# 4ï¸âƒ£ Despliegue y Monitoreo de Aplicaciones GenAI

## ğŸ“š Tabla de Contenidos
1. [Ciclo de Vida de Sistemas GenAI](#ciclo-de-vida-de-sistemas-genai)
2. [Empaquetado de Modelos](#empaquetado-de-modelos-genai)
3. [MLflow para Deployment](#mlflow-para-deployment)
4. [MÃ©todos de Despliegue](#mÃ©todos-de-despliegue)
5. [Databricks Model Serving](#databricks-model-serving)
6. [Monitoreo de Sistemas AI](#monitoreo-de-sistemas-ai)
7. [MLOps y LLMOps](#mlops-y-llmops)

---

## Ciclo de Vida de Sistemas GenAI

### Fase 1: System Development (Desarrollo)

**CaracterÃ­sticas**: Trabaja con **datos estÃ¡ticos**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DEFINIR PROBLEMA                   â”‚
â”‚     Â¿QuÃ© debe resolver el sistema?     â”‚
â”‚                                        â”‚
â”‚     Ejemplo:                           â”‚
â”‚     "Chatbot que responde preguntas    â”‚
â”‚      sobre productos"                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ESTABLECER MÃ‰TRICAS                â”‚
â”‚     Â¿CÃ³mo medir el Ã©xito?              â”‚
â”‚                                        â”‚
â”‚     Ejemplo:                           â”‚
â”‚     â€¢ PrecisiÃ³n > 85%                  â”‚
â”‚     â€¢ Latencia < 2 segundos            â”‚
â”‚     â€¢ SatisfacciÃ³n usuario > 4/5       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. RECOPILAR DATOS                    â”‚
â”‚     Obtener datos relevantes           â”‚
â”‚                                        â”‚
â”‚     Ejemplo:                           â”‚
â”‚     â€¢ FAQs                             â”‚
â”‚     â€¢ Emails de soporte                â”‚
â”‚     â€¢ DocumentaciÃ³n de productos       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PROCESAR DATOS                     â”‚
â”‚     Limpiar y estructurar              â”‚
â”‚                                        â”‚
â”‚     â€¢ Eliminar duplicados              â”‚
â”‚     â€¢ Normalizar texto                 â”‚
â”‚     â€¢ Convertir formatos               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. CONSTRUIR SISTEMA                  â”‚
â”‚     Implementar soluciÃ³n               â”‚
â”‚                                        â”‚
â”‚     â€¢ RAG (bÃºsqueda + generaciÃ³n)      â”‚
â”‚     â€¢ Chains (flujos estructurados)    â”‚
â”‚     â€¢ Agents (si necesario)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. EVALUAR                            â”‚
â”‚     Probar contra mÃ©tricas             â”‚
â”‚                                        â”‚
â”‚     â€¢ Pruebas manuales                 â”‚
â”‚     â€¢ MÃ©tricas automatizadas           â”‚
â”‚     â€¢ Feedback de usuarios piloto      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Fase 2: Deployment & Production (ProducciÃ³n)

**CaracterÃ­sticas**: Datos **nuevos y cambiantes** en tiempo real

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DEPLOYMENT                         â”‚
â”‚     Llevar a producciÃ³n                â”‚
â”‚                                        â”‚
â”‚     â€¢ API REST                         â”‚
â”‚     â€¢ Chatbot web                      â”‚
â”‚     â€¢ AplicaciÃ³n mÃ³vil                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. MONITOREO                          â”‚
â”‚     Vigilar comportamiento             â”‚
â”‚                                        â”‚
â”‚     â€¢ Detectar degradaciÃ³n             â”‚
â”‚     â€¢ Identificar errores              â”‚
â”‚     â€¢ Medir drift de datos             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. ITERACIÃ“N (si hay problemas)       â”‚
â”‚                                        â”‚
â”‚     â”Œâ”€â”€> Recolectar nuevos datos      â”‚
â”‚     â”œâ”€â”€> Reentrenar sistema           â”‚
â”‚     â”œâ”€â”€> Reprocesar datos             â”‚
â”‚     â””â”€â”€> Re-deployment                â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AnalogÃ­a PrÃ¡ctica

**PiÃ©nsalo como desarrollar una app mÃ³vil**:

**Fase 1 (Development)**: 
- Programas la app en tu computadora
- Pruebas con datos de prueba
- Arreglas bugs
- Funciona perfecto en tu entorno

**Fase 2 (Production)**:
- Publicas en App Store
- Miles de usuarios la descargan
- Descubres nuevos bugs en escenarios reales
- Usuarios usan la app de formas inesperadas
- Tienes que actualizar regularmente

---

## Empaquetado de Modelos GenAI

### Formas de Empaquetar LÃ³gica GenAI

Con LLMs, la "lÃ³gica ML" se empaqueta de nuevas formas:

#### 1. Engineered Prompt (Prompt DiseÃ±ado)

**QuÃ© es**: Prompt cuidadosamente diseÃ±ado que se guarda como plantilla

**Ejemplo**:
```python
PROMPT_TEMPLATE = """
Eres un asistente mÃ©dico experto.

Contexto del paciente:
{patient_history}

Pregunta:
{question}

Instrucciones:
- Usa terminologÃ­a mÃ©dica precisa
- Cita fuentes cuando sea posible
- Si no estÃ¡s seguro, di "Consulta con un mÃ©dico"

Respuesta:
"""
```

**CÃ³mo se empaqueta**:
- Guardar como archivo `.txt` o `.yaml`
- Versionar en Git
- Cargar dinÃ¡micamente en runtime

---

#### 2. Chain (Secuencia Estructurada)

**QuÃ© es**: Secuencia de pasos desde frameworks como LangChain o LlamaIndex

**Ejemplo**:
```python
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI

# Definir chain
chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

# Usar
answer = chain.run("Â¿QuÃ© es RAG?")
```

**CÃ³mo se empaqueta**:
- Serializar con `mlflow.langchain.log_model(chain)`
- Incluye todas las dependencias
- Reproducible en cualquier entorno

---

#### 3. API Call (Llamada Ligera a API)

**QuÃ© es**: Llamada simple a un LLM vÃ­a API

**Tipos**:

##### a) API Externa Propietaria
```python
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hola"}]
)
```

**Ventajas**:
- âœ… FÃ¡cil de usar
- âœ… Sin infraestructura

**Desventajas**:
- âŒ Dependencia externa
- âŒ Costo por uso
- âŒ Datos salen de tu infraestructura

##### b) API Interna (Self-Hosted)
```python
import requests

response = requests.post(
    "https://mi-databricks.cloud/serving-endpoints/mi-llm",
    json={"prompt": "Hola"}
)
```

**Ventajas**:
- âœ… Control total
- âœ… Datos privados
- âœ… Customizable (fine-tuned)

**Tipos de modelos internos**:
- **Fine-tuned**: Ajustado a tu dominio
- **Pre-trained**: Sin modificar

---

#### 4. InvocaciÃ³n Local con GPU

**QuÃ© es**: Ejecutar modelo localmente (no vÃ­a API)

**Ejemplo**:
```python
from transformers import pipeline

generator = pipeline(
    "text-generation",
    model="meta-llama/Llama-2-7b-hf",
    device=0  # GPU 0
)

output = generator("Hola, Â¿cÃ³mo estÃ¡s?")
```

**CuÃ¡ndo usar**:
- Edge deployments (dispositivos IoT)
- Sin conexiÃ³n a internet
- Latencia ultra-baja requerida

**Desventajas**:
- âŒ Requiere GPU/hardware potente
- âŒ Mantenimiento de infraestructura

---

### Resumen de Opciones

| MÃ©todo | Complejidad | Control | Costo | CuÃ¡ndo Usar |
|--------|-------------|---------|-------|-------------|
| **Prompt** | Baja | Bajo | Variable | Prototipo rÃ¡pido |
| **Chain** | Media | Medio | Variable | Apps estructuradas |
| **API Externa** | Baja | Bajo | Alto | MVP, pruebas |
| **API Interna** | Alta | Alto | Medio | ProducciÃ³n empresarial |
| **Local GPU** | Alta | Total | Bajo (si ya tienes HW) | Edge, offline |

---

## MLflow para Deployment

### Â¿QuÃ© es MLflow?

**Recordatorio**: Plataforma open-source para gestionar **ciclo de vida completo** de ML/GenAI

### MLflow Model (Formato EstÃ¡ndar)

**Estructura**:
```
mi_modelo/
â”œâ”€â”€ MLmodel              # Metadata (flavors, signature)
â”œâ”€â”€ conda.yaml           # Dependencias (conda)
â”œâ”€â”€ requirements.txt     # Dependencias (pip)
â”œâ”€â”€ python_env.yaml      # VersiÃ³n Python
â”œâ”€â”€ model/               # Archivos del modelo
â”‚   â”œâ”€â”€ model.pkl
â”‚   â””â”€â”€ tokenizer/
â””â”€â”€ input_example.json   # Ejemplo de input
```

#### MLmodel File
```yaml
artifact_path: model
flavors:
  langchain:
    langchain_version: 0.0.200
    model_data: model
  python_function:
    env: conda.yaml
    loader_module: mlflow.langchain
    python_version: 3.10.12
signature:
  inputs: '[{"name": "query", "type": "string"}]'
  outputs: '[{"name": "answer", "type": "string"}]'
```

---

### mlflow.pyfunc (Python Function Flavor)

**QuÃ© es**: **Interfaz genÃ©rica** para cualquier modelo Python

**Por quÃ© es importante**:
- Cualquier modelo MLflow puede cargarse como Python function
- Interfaz unificada para deployment
- Compatible con Model Serving

**Funciones Clave**:
```python
import mlflow

# Guardar modelo
mlflow.pyfunc.log_model(
    artifact_path="model",
    python_model=mi_modelo,
    signature=signature,
    input_example=input_example
)

# Cargar modelo
loaded_model = mlflow.pyfunc.load_model("models:/mi_modelo/1")

# Predecir
result = loaded_model.predict({"query": "Â¿QuÃ© es RAG?"})
```

---

### MLflow Registry en Unity Catalog

**CaracterÃ­sticas**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UNITY CATALOG MODEL REGISTRY           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Versioning automÃ¡tico               â”‚
â”‚     â€¢ Version 1, 2, 3, ...              â”‚
â”‚                                         â”‚
â”‚  âœ… Aliases                             â”‚
â”‚     â€¢ @champion (mejor modelo)          â”‚
â”‚     â€¢ @challenger (candidato)           â”‚
â”‚     â€¢ @staging                          â”‚
â”‚                                         â”‚
â”‚  âœ… Lifecycle Management                â”‚
â”‚     â€¢ Development â†’ Staging â†’ Prod      â”‚
â”‚                                         â”‚
â”‚  âœ… Collaboration & ACLs                â”‚
â”‚     â€¢ QuiÃ©n puede leer/escribir         â”‚
â”‚     â€¢ Unity Catalog governance          â”‚
â”‚                                         â”‚
â”‚  âœ… Full Lineage                        â”‚
â”‚     â€¢ QuÃ© datos usÃ³                     â”‚
â”‚     â€¢ QuÃ© cÃ³digo                        â”‚
â”‚     â€¢ QuÃ© parÃ¡metros                    â”‚
â”‚                                         â”‚
â”‚  âœ… Tagging & Annotations               â”‚
â”‚     â€¢ Metadata custom                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo de Uso**:
```python
import mlflow

# Registrar en Unity Catalog
mlflow.set_registry_uri("databricks-uc")

with mlflow.start_run():
    # Entrenar/construir modelo
    model = build_my_rag_chain()
    
    # Loguear
    mlflow.langchain.log_model(
        model,
        "model",
        registered_model_name="mi_catalogo.mi_schema.chatbot_v1"
    )

# Establecer alias
from mlflow import MlflowClient
client = MlflowClient()

client.set_registered_model_alias(
    "mi_catalogo.mi_schema.chatbot_v1",
    "champion",
    version=3
)

# Cargar modelo por alias
champion_model = mlflow.langchain.load_model(
    "models:/mi_catalogo.mi_schema.chatbot_v1@champion"
)
```

---

### MLflow y Ciclo de Desarrollo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. MODEL/CHAIN BUILDING                â”‚
â”‚     â€¢ Construir RAG/Chain/Agent         â”‚
â”‚     â€¢ Experimentar con prompts          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. MLFLOW TRACKING                     â”‚
â”‚     â€¢ Registrar experimentos            â”‚
â”‚     â€¢ Comparar mÃ©tricas                 â”‚
â”‚     â€¢ Seleccionar mejor versiÃ³n         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. MLFLOW EVALUATION                   â”‚
â”‚     â€¢ Evaluar con datasets              â”‚
â”‚     â€¢ MÃ©tricas automatizadas            â”‚
â”‚     â€¢ LLM-as-a-judge                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. MLFLOW REGISTRY                     â”‚
â”‚     â€¢ Registrar modelo                  â”‚
â”‚     â€¢ Versionar                         â”‚
â”‚     â€¢ Asignar alias (@champion)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. MODEL DEPLOYMENT                    â”‚
â”‚     â€¢ Databricks Model Serving          â”‚
â”‚     â€¢ REST API                          â”‚
â”‚     â€¢ Monitoreo                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©todos de Despliegue

### 1. Batch Inference (Por Lotes)

**QuÃ© es**: Procesar **muchos datos a la vez** en un schedule

**CuÃ¡ndo usar**:
- Reportes diarios/semanales
- ETL jobs
- No se necesita respuesta inmediata

**Ejemplo**:
```
Tarea: "Resumir todos los reportes financieros del trimestre"

EjecuciÃ³n:
- Todos los domingos a las 2 AM
- Procesa 1000 documentos
- Genera resÃºmenes
- Los guarda en Delta Table

Usuarios:
- Lunes por la maÃ±ana ven resultados
```

#### âœ… Ventajas
- **MÃ¡s barato**: Hardware se usa eficientemente
- **Alto volumen**: Procesa millones de registros
- **Eficiente**: Paraleliza bien

#### âŒ Limitaciones
- **Alta latencia**: Esperas horas/dÃ­as
- **Datos stale**: No es tiempo real
- **No para streaming**: Datos deben ser estÃ¡ticos

#### ImplementaciÃ³n con Spark
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

# Cargar datos
df = spark.table("mi_catalogo.mi_schema.documentos")

# UDF para procesar con LLM
def summarize_with_llm(text):
    # Llamar a LLM
    return summary

from pyspark.sql.functions import udf
summarize_udf = udf(summarize_with_llm)

# Aplicar a todos
df_summarized = df.withColumn("summary", summarize_udf("text"))

# Guardar
df_summarized.write.saveAsTable("mi_catalogo.mi_schema.summarized")
```

---

### 2. Streaming Inference (Flujo Continuo)

**QuÃ© es**: Procesar **datos conforme llegan** (stream)

**CuÃ¡ndo usar**:
- Procesamiento de eventos en tiempo real
- AnÃ¡lisis de logs
- IoT data

**Ejemplo**:
```
AplicaciÃ³n: "Personalizar mensajes de marketing en tiempo real"

Flujo:
Usuario hace clic â†’ Evento capturado â†’ 
Stream processor â†’ LLM personaliza mensaje â†’ 
Mensaje enviado (< 5 segundos)
```

#### Structured Streaming (Spark)
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

# Leer stream de Kafka
stream_df = spark.readStream \
    .format("kafka") \
    .option("subscribe", "user_events") \
    .load()

# Procesar con LLM
processed_df = stream_df.withColumn(
    "personalized_message",
    personalize_udf("event_data")
)

# Escribir resultados
query = processed_df.writeStream \
    .format("delta") \
    .outputMode("append") \
    .option("checkpointLocation", "/checkpoints") \
    .start("/output")
```

---

### 3. Real-Time Inference (Tiempo Real)

**QuÃ© es**: Generar predicciones **instantÃ¡neamente** cuando se solicitan

**CuÃ¡ndo usar**:
- Chatbots
- APIs interactivas
- Aplicaciones con usuarios esperando

**Ejemplo**:
```
Usuario: "Â¿CuÃ¡l es el estado de mi orden?"
â†“ (< 2 segundos)
API â†’ Model Serving â†’ LLM â†’ Response
â†“
Chatbot: "Tu orden #12345 estÃ¡ en camino, llegarÃ¡ maÃ±ana"
```

#### âœ… Ventajas
- **Baja latencia**: Respuestas en segundos
- **Interactivo**: UX fluida
- **Datos frescos**: Usa info actualizada

#### âŒ DesafÃ­os
- **Infraestructura compleja**: Auto-scaling, load balancing
- **Costo**: Servidores 24/7
- **Requiere expertise**: DevOps, SRE

#### Databricks Model Serving
```python
# Ya registrado en MLflow Registry
# Crear endpoint

from databricks.sdk import WorkspaceClient

w = WorkspaceClient()

w.serving_endpoints.create(
    name="chatbot-endpoint",
    config={
        "served_models": [{
            "model_name": "mi_catalogo.mi_schema.chatbot",
            "model_version": "3",
            "workload_size": "Small",  # Small, Medium, Large
            "scale_to_zero_enabled": True  # Ahorra costos
        }]
    }
)

# Llamar API
import requests

response = requests.post(
    "https://mi-workspace.cloud.databricks.com/serving-endpoints/chatbot-endpoint/invocations",
    headers={"Authorization": f"Bearer {token}"},
    json={"inputs": {"query": "Â¿Estado de mi orden?"}}
)
```

---

### 4. Embedded/Edge Inference

**QuÃ© es**: Ejecutar modelo **en el dispositivo** (sin cloud)

**CuÃ¡ndo usar**:
- IoT devices
- Aplicaciones mÃ³viles offline
- Latencia ultra-baja (milisegundos)

**Ejemplo**:
```
Auto autÃ³nomo:
CÃ¡mara â†’ Procesamiento local (GPU en auto) â†’ DecisiÃ³n â†’ AcciÃ³n
(No puede depender de internet)
```

**Ejemplo**: Modificar temperatura del aire acondicionado con voz

---

### ComparaciÃ³n de MÃ©todos

| MÃ©todo | Latencia | Costo | Complejidad | Mejor Para |
|--------|----------|-------|-------------|------------|
| **Batch** | Alta (horas) | Bajo | Baja | Reportes, ETL |
| **Streaming** | Media (segundos) | Medio | Media | Eventos, IoT |
| **Real-Time** | Baja (< 2s) | Alto | Alta | Chatbots, APIs |
| **Edge** | Muy baja (ms) | Variable | Alta | Offline, IoT crÃ­tico |

---

## ğŸ“¦ APPLICATIONS en Databricks

Estos tres componentes representan la **etapa de producciÃ³n y operaciÃ³n** de tus modelos:

- **MLflow AI Gateway**: CÃ³mo se exponen vÃ­a API
- **Model Serving**: CÃ³mo se sirven eficientemente  
- **Lakehouse Monitoring**: CÃ³mo se supervisan en tiempo real

---

### ğŸ§© 1. MLflow AI Gateway

La **puerta de entrada unificada** (API Gateway) para acceder a modelos de IA â€”tanto internos como externosâ€” de forma segura y estandarizada.

**Â¿QuÃ© hace?**:
- âœ… Proporciona una **interfaz Ãºnica** para interactuar con cualquier modelo LLM:
  - **Interno** (registrado en MLflow o Mosaic AI)
  - **Externo** (OpenAI, Anthropic, Hugging Face, Azure AI, AWS Bedrock, etc.)
- âœ… Controla **costos, autenticaciÃ³n y trazabilidad** de las llamadas
- âœ… Permite a los equipos usar LLMs **sin exponer claves API individuales**

**Problema que resuelve**:
```
âŒ Sin AI Gateway:
Equipo A â†’ usa OpenAI directamente (API key hardcodeada)
Equipo B â†’ usa Anthropic (otra key)
Equipo C â†’ usa modelo interno (config diferente)
â†’ Caos de credenciales
â†’ No hay tracking centralizado
â†’ Costos incontrolables

âœ… Con MLflow AI Gateway:
Todos los equipos â†’ AI Gateway â†’ Enruta a modelo apropiado
â†’ Keys centralizadas y seguras
â†’ Logging automÃ¡tico
â†’ Control de costos
```

**Arquitectura**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  APLICACIÃ“N / USUARIO                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MLFLOW AI GATEWAY                       â”‚
â”‚  â€¢ AutenticaciÃ³n                         â”‚
â”‚  â€¢ Rate limiting                         â”‚
â”‚  â€¢ Cost tracking                         â”‚
â”‚  â€¢ Logging                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â†“               â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI   â”‚  â”‚ Anthropicâ”‚  â”‚ DBRX     â”‚
â”‚ GPT-4    â”‚  â”‚ Claude   â”‚  â”‚ Internal â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo de Uso**:
```python
from mlflow.deployments import get_deploy_client

# Cliente del gateway
client = get_deploy_client("databricks")

# Llamar a GPT-4 (sin exponer API key)
response = client.predict(
    endpoint="chat-gpt-4",
    inputs={
        "messages": [
            {"role": "user", "content": "Explica RAG"}
        ]
    }
)

# Llamar a Claude (misma interfaz)
response_claude = client.predict(
    endpoint="chat-claude",
    inputs={
        "messages": [
            {"role": "user", "content": "Explica RAG"}
        ]
    }
)

# Todas las llamadas se loguean automÃ¡ticamente
```

**Ventajas**:
- ğŸ” **Seguridad**: Keys centralizadas
- ğŸ’° **Control de costos**: Tracking unificado
- ğŸ“Š **Observabilidad**: Logging automÃ¡tico
- ğŸ”„ **Flexibilidad**: Cambiar de proveedor sin cambiar cÃ³digo

---

### âš™ï¸ 2. Databricks Model Serving

Servicio que **despliega modelos** de Machine Learning o LLMs como **endpoints REST en producciÃ³n**, optimizados para baja latencia y alta disponibilidad.

**Tipos de Modelos Soportados**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATABRICKS MODEL SERVING               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. CUSTOM MODELS (MLflow)              â”‚
â”‚     â€¢ Tu modelo registrado en UC        â”‚
â”‚     â€¢ Chains, RAGs, Agents custom       â”‚
â”‚     â€¢ Python, PyTorch, TensorFlow       â”‚
â”‚                                         â”‚
â”‚  2. FOUNDATION MODELS                   â”‚
â”‚     â€¢ DBRX Instruct                     â”‚
â”‚     â€¢ LLaMA 3 (8B, 70B)                 â”‚
â”‚     â€¢ Mixtral 8x7B                      â”‚
â”‚     â€¢ BGE-Large (embeddings)            â”‚
â”‚                                         â”‚
â”‚  3. EXTERNAL MODELS                     â”‚
â”‚     â€¢ OpenAI (GPT-4, GPT-3.5)           â”‚
â”‚     â€¢ Anthropic (Claude)                â”‚
â”‚     â€¢ Cohere                            â”‚
â”‚     â€¢ AWS Bedrock models                â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas Clave**:

| FunciÃ³n | DescripciÃ³n | Ventaja |
|---------|-------------|---------|
| **Tiempo Real** | Respuestas instantÃ¡neas | Chatbots, APIs interactivas |
| **Batch Inference** | Procesamiento masivo | Reportes periÃ³dicos |
| **IntegraciÃ³n MLflow** | Deploy directo desde Registry | Sin configuraciÃ³n manual |
| **Security UC** | Control de acceso via Unity Catalog | Gobernanza empresarial |
| **Inference Tables** | Guarda cada predicciÃ³n | AuditorÃ­a y debugging |
| **Auto-scaling** | Escala segÃºn demanda | Optimiza costos |
| **Scale-to-zero** | Apaga cuando no se usa | Ahorra costos |

---

### Inference Tables (Tablas de Inferencia)

**QuÃ© son**: Cada request-response se guarda automÃ¡ticamente en una **Delta Table**

**Para quÃ© sirve**:
- âœ… Monitoreo posterior
- âœ… Debugging
- âœ… AnÃ¡lisis de uso
- âœ… Re-entrenamiento (feedback loop)

**Estructura**:
```
Inference Table:
â”œâ”€â”€ request_id
â”œâ”€â”€ timestamp
â”œâ”€â”€ input (query del usuario)
â”œâ”€â”€ output (respuesta del LLM)
â”œâ”€â”€ latency
â”œâ”€â”€ token_count
â””â”€â”€ metadata
```

**Habilitarlo**:
```python
w.serving_endpoints.create(
    name="mi-endpoint",
    config={
        "served_models": [{ ... }],
        "traffic_config": { ... },
        "auto_capture_config": {
            "catalog_name": "mi_catalogo",
            "schema_name": "mi_schema",
            "table_name_prefix": "inference_"
        }
    }
)
```

**Resultado**: Se crea automÃ¡ticamente:
```
mi_catalogo.mi_schema.inference_mi-endpoint
```

---

### A/B Testing y Canary Deployments

#### Traffic Splitting

**Ejemplo**: Probar nuevo modelo con 10% de trÃ¡fico

```python
w.serving_endpoints.update_config(
    name="mi-endpoint",
    config={
        "served_models": [
            {
                "model_name": "mi_catalogo.mi_schema.chatbot",
                "model_version": "3",  # VersiÃ³n vieja
                "workload_size": "Small"
            },
            {
                "model_name": "mi_catalogo.mi_schema.chatbot",
                "model_version": "4",  # VersiÃ³n nueva
                "workload_size": "Small"
            }
        ],
        "traffic_config": {
            "routes": [
                {"served_model_name": "chatbot-3", "traffic_percentage": 90},
                {"served_model_name": "chatbot-4", "traffic_percentage": 10}
            ]
        }
    }
)
```

**Flujo**:
```
100 requests
â”œâ”€> 90 requests â†’ Modelo v3
â””â”€> 10 requests â†’ Modelo v4

Analizar mÃ©tricas de v4:
- Si mejor: aumentar % gradualmente
- Si peor: volver a 100% v3
```

---

### IntegraciÃ³n con Unity Catalog

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UNITY CATALOG                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â€¢ UC Volume                            â”‚
â”‚    â””â”€> Archivos (PDFs, CSVs, etc.)     â”‚
â”‚                                         â”‚
â”‚  â€¢ Raw/Processed Text Tables            â”‚
â”‚    â””â”€> Documentos procesados            â”‚
â”‚                                         â”‚
â”‚  â€¢ Embeddings/Index                     â”‚
â”‚    â””â”€> Vector Search index              â”‚
â”‚                                         â”‚
â”‚  â€¢ Model/Chain                          â”‚
â”‚    â””â”€> Modelo registrado                â”‚
â”‚                                         â”‚
â”‚  â€¢ Inference Table                      â”‚
â”‚    â””â”€> Logs de requests                 â”‚
â”‚                                         â”‚
â”‚  â€¢ Processed Payloads Table             â”‚
â”‚    â””â”€> Datos procesados                 â”‚
â”‚                                         â”‚
â”‚  â€¢ Metric Tables                        â”‚
â”‚    â””â”€> Lakehouse Monitoring             â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Todo en Unity Catalog** = Gobernanza centralizada

---

## Monitoreo de Sistemas AI

### Â¿Por quÃ© Monitorear?

**Objetivo**: Diagnosticar problemas **antes** de que sean severos o costosos

**Sin monitoreo**:
```
Usuario: "El chatbot da respuestas raras"
â†’ Â¿CuÃ¡ndo empezÃ³?
â†’ Â¿CuÃ¡ntos usuarios afectados?
â†’ Â¿QuÃ© inputs causan el problema?
â†’ â“ No sabemos
```

**Con monitoreo**:
```
Alerta automÃ¡tica: "Aumento del 30% en respuestas de baja calidad desde las 2 PM"
â†’ Sabemos exactamente cuÃ¡ndo y cuÃ¡nto
â†’ Vemos los inputs problemÃ¡ticos
â†’ Podemos actuar rÃ¡pido
```

---

### Â¿QuÃ© Monitorear?

#### 1. Input Data
- DistribuciÃ³n de queries
- Longitud de inputs
- Idiomas usados
- DetecciÃ³n de inputs maliciosos (prompt injection)

#### 2. Data en Vector Databases
- Calidad de documentos
- Coverage de temas
- Actualidad de informaciÃ³n

#### 3. Human Feedback
- ğŸ‘ğŸ‘ reactions
- Comentarios de usuarios
- Ratings (1-5 estrellas)

#### 4. Prompts/Queries y Responses
- Guardar para anÃ¡lisis
- âš ï¸ **Legalidad**: Â¿Puedes almacenar datos de usuarios?
- Privacy compliance (GDPR, CCPA)

---

### AI Assets a Monitorear

#### 1. Mid-Training Checkpoints
- Si estÃ¡s fine-tuning, checkpoints periÃ³dicos
- AnÃ¡lisis de loss curves

#### 2. Component Evaluation Metrics
- Retrieval quality
- Embedding quality
- Reranking effectiveness

#### 3. System Evaluation Metrics
- End-to-end latency
- Token usage (costo)
- Answer quality

#### 4. Performance & Cost
- Requests per second (RPS)
- P50, P95, P99 latency
- GPU utilization
- Cost per request

---

### ğŸ“Š 3. Lakehouse Monitoring

SoluciÃ³n **totalmente gestionada** para monitorear el comportamiento, rendimiento y calidad de **modelos en producciÃ³n** (ML y GenAI).

**Â¿QuÃ© monitorea?**:
- âœ… **Datos de entrada y salida** â†’ Detectar data drift o degradaciÃ³n de calidad
- âœ… **Rendimiento del modelo** â†’ Latencia, costos, errores
- âœ… **MÃ©tricas personalizadas** â†’ PrecisiÃ³n, fidelidad, relevancia
- âœ… **Tendencias a lo largo del tiempo** â†’ Dashboards automÃ¡ticos en Databricks SQL

**Arquitectura Interna**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INFERENCE TABLE (Delta Table)           â”‚
â”‚  â€¢ request_id                            â”‚
â”‚  â€¢ timestamp                             â”‚
â”‚  â€¢ input (query)                         â”‚
â”‚  â€¢ output (response)                     â”‚
â”‚  â€¢ latency, tokens, metadata             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAKEHOUSE MONITORING                    â”‚
â”‚  â€¢ Analiza periÃ³dicamente                â”‚
â”‚  â€¢ Genera mÃ©tricas automÃ¡ticas           â”‚
â”‚  â€¢ Detecta drift, anomalÃ­as              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â†“               â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Profile  â”‚  â”‚  Drift   â”‚  â”‚ Custom   â”‚
â”‚ Metrics  â”‚  â”‚ Metrics  â”‚  â”‚ Metrics  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚             â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATABRICKS SQL DASHBOARD                â”‚
â”‚  â€¢ Visualizaciones automÃ¡ticas           â”‚
â”‚  â€¢ Alertas configurables                 â”‚
â”‚  â€¢ HistÃ³rico de mÃ©tricas                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**CaracterÃ­sticas Clave**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAKEHOUSE MONITORING                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… Fully Managed                       â”‚
â”‚     â€¢ Zero ops overhead                 â”‚
â”‚     â€¢ No infraestructura que mantener   â”‚
â”‚                                         â”‚
â”‚  âœ… Frictionless                        â”‚
â”‚     â€¢ Setup en minutos                  â”‚
â”‚     â€¢ ConfiguraciÃ³n simple              â”‚
â”‚                                         â”‚
â”‚  âœ… Unified                             â”‚
â”‚     â€¢ Datos + Modelos en un lugar       â”‚
â”‚     â€¢ Todo en Unity Catalog             â”‚
â”‚                                         â”‚
â”‚  âœ… Built on Unity Catalog              â”‚
â”‚     â€¢ ACLs integradas                   â”‚
â”‚     â€¢ Governance automÃ¡tico             â”‚
â”‚                                         â”‚
â”‚  ğŸ“Š Auto-generates DBSQL Dashboard      â”‚
â”‚     â€¢ Visualizaciones listas            â”‚
â”‚     â€¢ GrÃ¡ficos interactivos             â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tipos de MÃ©tricas

**1. Profile Metrics**:
- EstadÃ­sticas de datos (min, max, mean, std)
- Distribuciones
- Nulls, missings

**2. Drift Metrics**:
- Â¿Los datos cambiaron vs baseline?
- Distributional drift
- Statistical tests (KS, Ï‡Â²)

**3. Custom Metrics**:
- Defines las tuyas
- Ejemplo: "% de respuestas > 500 palabras"

---

#### Setup de Lakehouse Monitoring

```python
from databricks import lakehouse_monitoring as lm

# Monitorear inference table
lm.create_monitor(
    table_name="mi_catalogo.mi_schema.inference_chatbot",
    profile_type=lm.InferenceLog(
        timestamp_col="timestamp",
        model_id_col="model_version",
        prediction_col="output",
        problem_type="text-generation",
        label_col=None  # No tenemos ground truth en tiempo real
    ),
    output_schema_name="mi_catalogo.mi_schema",
    schedule=lm.MonitorCronSchedule(
        quartz_cron_expression="0 0 * * * ?"  # Cada hora
    )
)
```

**Resultado automÃ¡tico**:
1. **Profile Table**: EstadÃ­sticas por ventana de tiempo
2. **Drift Table**: MÃ©tricas de drift
3. **Dashboard**: VisualizaciÃ³n en Databricks SQL

---

### Workflow de Monitoreo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DESARROLLO                             â”‚
â”‚  â€¢ Crear monitoring tables para todos   â”‚
â”‚    los componentes                      â”‚
â”‚  â€¢ Definir mÃ©tricas clave               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TESTING                                â”‚
â”‚  â€¢ Validar que monitoring funciona      â”‚
â”‚  â€¢ Ajustar thresholds de alertas       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRODUCCIÃ“N                             â”‚
â”‚  â€¢ Refresh regular de tablas            â”‚
â”‚  â€¢ Alertas configuradas                 â”‚
â”‚  â€¢ Dashboards monitoreados              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ACCIÃ“N                                 â”‚
â”‚  â€¢ Si hay problemas:                    â”‚
â”‚    - Investigar causa raÃ­z              â”‚
â”‚    - Recolectar nuevos datos            â”‚
â”‚    - Reentrenar/ajustar                 â”‚
â”‚    - Re-deployment                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Tips**:
- âœ… **Modelar costo vs performance**: Â¿Vale la pena modelo mÃ¡s caro?
- âœ… **Refresh regular**: Hourly, daily (segÃºn criticidad)
- âœ… **Alertas clave**: No todas las mÃ©tricas, solo las crÃ­ticas
- âœ… **Retrain triggers**: Automatizar si drift > threshold

---

## MLOps y LLMOps

### Â¿QuÃ© es MLOps?

**DefiniciÃ³n**: Conjunto de **procesos y automatizaciÃ³n** para gestionar datos, cÃ³digo y modelos, mejorando performance, estabilidad y eficiencia de sistemas ML.

**FÃ³rmula**:
```
MLOps = DataOps + DevOps + ModelOps
```

**Componentes**:
- **DataOps**: GestiÃ³n de datos (calidad, pipelines, versioning)
- **DevOps**: CI/CD, infrastructure as code, deployment
- **ModelOps**: GestiÃ³n de modelos (training, evaluation, deployment, monitoring)

---

### Â¿Por quÃ© importa MLOps?

| Beneficio | DescripciÃ³n |
|-----------|-------------|
| **Calidad de datos** | Datos limpios y confiables |
| **Procesos optimizados** | Menos manual work, mÃ¡s automatizaciÃ³n |
| **Monitoreo de costo/performance** | Optimizar ROI |
| **Time to value** | MÃ¡s rÃ¡pido a producciÃ³n |
| **Menos oversight manual** | Automatizar checks |

---

### Multi-Environment Semantics

**Entornos estÃ¡ndar**:
```
1. DEVELOPMENT (Dev)
   â€¢ ExperimentaciÃ³n
   â€¢ Breaking changes permitidos
   â€¢ Datos sintÃ©ticos/muestreados

2. STAGING (Stage)
   â€¢ Pre-producciÃ³n
   â€¢ Testing riguroso
   â€¢ Datos similares a prod

3. PRODUCTION (Prod)
   â€¢ Usuarios reales
   â€¢ Alta disponibilidad
   â€¢ Monitoreo 24/7
```

---

### SeparaciÃ³n de Entornos

#### OpciÃ³n 1: Direct Separation

**Estrategia**: **Workspaces de Databricks completamente separados**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dev Workspace   â”‚  â”‚ Stage Workspace  â”‚  â”‚  Prod Workspace  â”‚
â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚
â”‚  â€¢ Experimentos  â”‚  â”‚  â€¢ Pre-prod      â”‚  â”‚  â€¢ Usuarios      â”‚
â”‚  â€¢ Datos sample  â”‚  â”‚  â€¢ Testing       â”‚  â”‚  â€¢ Alta disp.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- âœ… Aislamiento completo
- âœ… No hay riesgo de afectar prod
- âœ… Escala a mÃºltiples proyectos

**Contras**:
- âŒ MÃ¡s infraestructura
- âŒ MÃ¡s complejidad de permisos

---

#### OpciÃ³n 2: Indirect Separation

**Estrategia**: **Un solo workspace con separaciÃ³n lÃ³gica** (catÃ¡logos, schemas, prefijos)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Databricks Workspace                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CatÃ¡logo: dev_catalog                  â”‚
â”‚    â””â”€> Schema: chatbot                  â”‚
â”‚                                         â”‚
â”‚  CatÃ¡logo: staging_catalog              â”‚
â”‚    â””â”€> Schema: chatbot                  â”‚
â”‚                                         â”‚
â”‚  CatÃ¡logo: prod_catalog                 â”‚
â”‚    â””â”€> Schema: chatbot                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pros**:
- âœ… Menos infraestructura
- âœ… Permisos mÃ¡s simples

**Contras**:
- âŒ Riesgo de mezclar entornos
- âŒ No escala bien a mÃºltiples proyectos

---

### Arquitectura Recomendada (MLOps)

**Deploy-Code Architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SOURCE CONTROL (Git)                      â”‚
â”‚  â€¢ CÃ³digo                                  â”‚
â”‚  â€¢ Configuraciones                         â”‚
â”‚  â€¢ Infrastructure as Code                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€â”€â”€â”€â”€> Dev Workspace
              â”œâ”€â”€â”€â”€â”€> Staging Workspace
              â””â”€â”€â”€â”€â”€> Prod Workspace
              
CI/CD Pipeline:
  Git Push â†’ Tests â†’ Build â†’ 
  Deploy to Dev â†’ Tests â†’ 
  Deploy to Staging â†’ Tests â†’ 
  Manual Approval â†’ Deploy to Prod
```

---

### LLMOps: Diferencias con MLOps Tradicional

| Aspecto | MLOps Tradicional | LLMOps |
|---------|-------------------|--------|
| **Dev Patterns** | CÃ³digo + datos | **+ Text templates (prompts)** |
| **Packaging** | Modelo serializado | **Aplicaciones completas (chains)** |
| **Serving** | Model endpoint | **+ Vector DB, GPU infra, UI** |
| **API Governance** | Menos crÃ­tico | **CrÃ­tico** (acceso a endpoints) |
| **Cost** | Fijo (infra) | **Variable** (uso, API calls) |
| **Human Feedback** | Opcional | **Esencial** (mejorar prompts) |

---

### LLMOps: Aspectos EspecÃ­ficos

#### 1. Incremental Development
- Iterar prompts
- Ajustar chains sin reentrenar

#### 2. Text Templates
- Versionar prompts como cÃ³digo
- A/B testing de prompts

#### 3. Entire Applications
- No solo modelo, toda la app (retriever + LLM + UI)

#### 4. Additional Components
- Vector databases
- Embedding services
- Rerankers

#### 5. GPU Infrastructure
- Requiere GPUs potentes
- OptimizaciÃ³n de batch size, quantization

#### 6. Cost Management
- API-based models: pay-per-token
- TÃ©cnicas para reducir costo:
  - Usar modelos mÃ¡s pequeÃ±os cuando sea posible
  - Caching de respuestas comunes
  - Prompt compression

#### 7. Human Feedback Loop
- Recolectar feedback (thumbs up/down)
- Usar para mejorar prompts
- Fine-tuning con feedback

---

### Arquitectura LLMOps Recomendada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DEVELOPMENT                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Experiment with prompts                 â”‚
â”‚  â€¢ Build chains/RAGs                       â”‚
â”‚  â€¢ Unit test components                    â”‚
â”‚  â€¢ MLflow tracking                         â”‚
â”‚                                            â”‚
â”‚  Dev Workspace                             â”‚
â”‚    dev_catalog.chatbot.models              â”‚
â”‚    dev_vector_search_index                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGING                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Integration testing                     â”‚
â”‚  â€¢ Performance testing                     â”‚
â”‚  â€¢ Canary deployment                       â”‚
â”‚  â€¢ Evaluation with test set                â”‚
â”‚                                            â”‚
â”‚  Staging Workspace                         â”‚
â”‚    staging_catalog.chatbot.models          â”‚
â”‚    staging_vector_search_index             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRODUCTION                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Model Serving (auto-scaling)            â”‚
â”‚  â€¢ Lakehouse Monitoring                    â”‚
â”‚  â€¢ Human feedback collection               â”‚
â”‚  â€¢ Inference tables logging                â”‚
â”‚                                            â”‚
â”‚  Prod Workspace                            â”‚
â”‚    prod_catalog.chatbot.models@champion    â”‚
â”‚    prod_vector_search_index                â”‚
â”‚    prod_inference_logs                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Preguntas de PrÃ¡ctica

### Pregunta 1
**Â¿QuÃ© mÃ©todo de deployment es mejor para un chatbot interactivo?**

A) Batch  
B) Streaming  
C) Real-Time âœ…  
D) Edge

**Respuesta**: C - Chatbots requieren respuesta inmediata (< 2 segundos)

---

### Pregunta 2
**Â¿QuÃ© guardan las Inference Tables automÃ¡ticamente?**

A) Solo los inputs  
B) Solo los outputs  
C) Requests y responses completos âœ…  
D) Solo mÃ©tricas agregadas

**Respuesta**: C - Cada request-response se loguea para monitoreo

---

### Pregunta 3
**En A/B testing, Â¿quÃ© porcentaje darÃ­as a un modelo nuevo inicialmente?**

A) 50%  
B) 90%  
C) 10-20% âœ…  
D) 100%

**Respuesta**: C - Empiezas con poco trÃ¡fico para minimizar riesgo

---

### Pregunta 4
**Â¿QuÃ© componente de MLflow gestiona versiones y aliases de modelos?**

A) MLflow Tracking  
B) MLflow Registry âœ…  
C) MLflow Evaluation  
D) MLflow Projects

**Respuesta**: B - Registry = versioning, aliases, lifecycle

---

### Pregunta 5
**Â¿QuÃ© diferencia LLMOps de MLOps tradicional?**

A) LLMOps usa Python  
B) LLMOps incluye text templates y human feedback âœ…  
C) LLMOps es mÃ¡s simple  
D) No hay diferencia

**Respuesta**: B - LLMOps aÃ±ade prompts, chains, feedback loop

---

## ğŸ“ Resumen Ejecutivo

### Lo que DEBES saber:

âœ… **Ciclo de Vida**: Development (datos estÃ¡ticos) â†’ Production (datos nuevos)  
âœ… **Empaquetado**: Prompt, Chain, API call (externa/interna), Local GPU  
âœ… **MLflow pyfunc**: Interfaz genÃ©rica para deployment  
âœ… **Unity Catalog Registry**: Versioning, aliases (@champion), lineage, ACLs  
âœ… **Deployment Methods**:
   - Batch = alto volumen, baja urgencia
   - Streaming = eventos en tiempo real
   - Real-Time = chatbots, APIs (< 2s)
   - Edge = offline, IoT

âœ… **Model Serving**: Custom, Foundation, External models  
âœ… **Inference Tables**: Auto-logging de requests para monitoreo  
âœ… **A/B Testing**: Traffic splitting para probar versiones  
âœ… **Lakehouse Monitoring**: Profile, Drift, Custom metrics  
âœ… **MLOps** = DataOps + DevOps + ModelOps  
âœ… **LLMOps** = MLOps + prompts + chains + human feedback + cost management

---

## ğŸ”— PrÃ³ximo Tema

â¡ï¸ **ContinÃºa con**: `05_Evaluacion_Gobernanza.md` (EvaluaciÃ³n, Seguridad, Guardrails, MÃ©tricas)

